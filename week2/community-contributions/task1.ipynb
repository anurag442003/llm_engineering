{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddfa9ae6-69fe-444a-b994-8c4c5970a7ec",
   "metadata": {},
   "source": [
    "# Student Contribution\n",
    "\n",
    "An awesome variation that includes a tool to make a booking! Thank you! -- Ed\n",
    "\n",
    "# Project - Airline AI Assistant with Booking Tool\n",
    "\n",
    "We'll now bring together what we've learned to make an AI Customer Support assistant for an Airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b50bbe2-c0b1-49c3-9a5c-1ba7efa2bcb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr\n",
    "import pandas as pd\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "747e8786-9da8-4342-b6c9-f5f69c2e22ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "MODEL = \"gemini-1.5-flash\"\n",
    "genai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a521d84-d07c-49ab-a0df-d6451499ed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bedabf-a0a7-4985-ad8e-07ed6a55a3a4",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "* Price and Booking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0696acb1-0b05-4dc2-80d5-771be04f1fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by making a useful function\n",
    "\n",
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4afceded-7178-4c05-8fa6-9f2085e6a344",
   "metadata": {},
   "outputs": [],
   "source": [
    "price_function = {\n",
    "    \"name\": \"get_ticket_price\",\n",
    "    \"description\": \"Get the price of a return ticket to the destination city, Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'.Be accurate, if you dont have price information for a particular ,destination say so.\",\n",
    "    \"parameters\": {\n",
    "        \"type\":\"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city that the customer wants to travel to\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"destination_city\"]\n",
    "    }\n",
    "}\n",
    "\n",
    "booking_function = {\n",
    "    \"name\": \"book_ticket\",\n",
    "    \"description\": \"Book a ticket to a destination city\",\n",
    "    \"parameters\": {\n",
    "        \"type\":\"OBJECT\",\n",
    "        \"properties\": {\n",
    "            \"destination_city\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The city the customer wants to travel to\"\n",
    "            },\n",
    "            \"num_tickets\": {\n",
    "                \"type\": \"integer\",\n",
    "                \"description\": \"The number of tickets to book\"\n",
    "            },\n",
    "            \"ticket_class\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"The class of the ticket (e.g., economy, business)\"\n",
    "            },\n",
    "            \"mail_address\": {\n",
    "                \"type\": \"string\",\n",
    "                \"description\": \"Mail address to send the ticket to\"\n",
    "            }\n",
    "        },\n",
    "        \"required\": [\"destination_city\", \"num_tickets\", \"ticket_class\", \"mail_address\"]\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d62733e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And this is included in a list of tools:\n",
    "\n",
    "tools = [{\"type\": \"function\", \"function\": price_function},\n",
    "         {\"type\": \"function\", \"function\": booking_function}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d3554f-b4e3-4ce7-af6f-68faa6dd2340",
   "metadata": {},
   "source": [
    "## Creating Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f671dbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating  ID for each booking\n",
    "# Produces IDs like 'BK-000001', 'BK-000002'\n",
    "\n",
    "booking_counter = 0\n",
    "\n",
    "def generate_unique_booking_id():\n",
    "    global booking_counter\n",
    "    booking_counter += 1\n",
    "    return f\"BK-{booking_counter:06d}\"  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77ae8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "bookingDB = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c73a0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_tool_call_gemini(function_call):\n",
    "    if function_call.name == \"get_ticket_price\":\n",
    "        args = function_call.args\n",
    "        destination_city = args.get('destination_city')\n",
    "        price = get_ticket_price(destination_city)\n",
    "        if price == \"Unknown\":\n",
    "            return f\"Sorry, we don't fly to {destination_city}. Available destinations are: {', '.join(ticket_prices.keys())}\"\n",
    "        return f\"The price for {destination_city} is {price}\"\n",
    "    \n",
    "    elif function_call.name == \"book_ticket\":\n",
    "        args = function_call.args\n",
    "        destination_city = args.get('destination_city')\n",
    "        num_tickets = args.get('num_tickets')\n",
    "        ticket_class = args.get('ticket_class')\n",
    "        mail_address = args.get('mail_address')\n",
    "        \n",
    "        # Get the ticket price\n",
    "        price_str = int(get_ticket_price(destination_city))\n",
    "        if price_str == \"Unknown\":\n",
    "            return f\"Sorry, we don't fly to {destination_city}. Available destinations are: {', '.join(ticket_prices.keys())}\"\n",
    "        price= int(price_str.replace(\"$\", \"\"))\n",
    "        total_price = price * num_tickets\n",
    "        \n",
    "        # Generate booking ID and save to DB (keeping existing logic)\n",
    "        booked_ID = generate_unique_booking_id()\n",
    "        data = {\n",
    "            \"booking_id\": [booked_ID],\n",
    "            \"mail_address\": [mail_address],\n",
    "            \"destination_city\": [destination_city],\n",
    "            \"num_tickets\": [num_tickets],\n",
    "            \"ticket_class\": [ticket_class],\n",
    "            \"total_price\": [total_price],\n",
    "        }\n",
    "        booking_temp = pd.DataFrame(data)\n",
    "        global bookingDB\n",
    "        bookingDB = bookingDB._append(booking_temp)\n",
    "        bookingDB.to_csv('bookingDB.csv', index=False)\n",
    "        \n",
    "        return f\"Booking confirmed! Booking ID: {booked_ID} for {num_tickets} {ticket_class} ticket(s) to {destination_city}. Total price: ${total_price}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f4afb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    # Initialize Gemini model\n",
    "    model = genai.GenerativeModel(MODEL)\n",
    "    chat = model.start_chat(history=[])  \n",
    "    # Add previous messages to chat history\n",
    "    for human, assistant in history:\n",
    "        chat.send_message(human)\n",
    "        chat.send_message(assistant)\n",
    "    \n",
    "    # Send current message with tools\n",
    "    response = chat.send_message(\n",
    "        message,\n",
    "        generation_config={\n",
    "            \"temperature\": 0.7\n",
    "        },\n",
    "        tools=[\n",
    "            {\n",
    "                \"function_declarations\": [price_function, booking_function]\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Check if function call is needed\n",
    "    if hasattr(response, 'candidates') and response.candidates[0].content.parts[0].function_call:\n",
    "        function_call = response.candidates[0].content.parts[0].function_call\n",
    "        tool_response = handle_tool_call_gemini(function_call)\n",
    "        \n",
    "        # Send follow-up with tool response\n",
    "        response = chat.send_message(\n",
    "            f\"Tool response: {tool_response}\",\n",
    "            generation_config={\"temperature\": 0.7}\n",
    "        )\n",
    "    \n",
    "    return response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4be8a71-b19e-4c2f-80df-f59ff2661f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\components\\chatbot.py:231: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\blocks.py\", line 2015, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\blocks.py\", line 1560, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\utils.py\", line 832, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\chat_interface.py\", line 649, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_17840\\2389538012.py\", line 12, in chat\n",
      "    response = chat.send_message(\n",
      "               ^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\google\\generativeai\\generative_models.py\", line 578, in send_message\n",
      "    response = self.model.generate_content(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\google\\generativeai\\generative_models.py\", line 331, in generate_content\n",
      "    response = self._client.generate_content(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py\", line 830, in generate_content\n",
      "    response = rpc(\n",
      "               ^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py\", line 131, in __call__\n",
      "    return wrapped_func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py\", line 293, in retry_wrapped_func\n",
      "    return retry_target(\n",
      "           ^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py\", line 153, in retry_target\n",
      "    _retry_error_helper(\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py\", line 212, in _retry_error_helper\n",
      "    raise final_exc from source_exc\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py\", line 144, in retry_target\n",
      "    result = target()\n",
      "             ^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\google\\api_core\\timeout.py\", line 120, in func_with_timeout\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py\", line 78, in error_remapped_callable\n",
      "    raise exceptions.from_grpc_error(exc) from exc\n",
      "google.api_core.exceptions.ResourceExhausted: 429 Resource has been exhausted (e.g. check quota).\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\blocks.py\", line 2015, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\blocks.py\", line 1560, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\utils.py\", line 832, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\chat_interface.py\", line 649, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_17840\\2389538012.py\", line 9, in chat\n",
      "    chat.send_message(assistant)\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\google\\generativeai\\generative_models.py\", line 564, in send_message\n",
      "    content = content_types.to_content(content)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py\", line 199, in to_content\n",
      "    raise ValueError(\n",
      "ValueError: Invalid input: 'content' argument must not be empty. Please provide a non-empty value.\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn=chat).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c9da69-d0cf-4cf2-a49e-e5669deec47b",
   "metadata": {},
   "source": [
    "## Enjoy, Happy Learning Thanks to Ed!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
