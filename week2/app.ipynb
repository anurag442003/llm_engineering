{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import json\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Markdown, display, update_display\n",
    "import gradio as gr \n",
    "import google.generativeai as genai \n",
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY',\"AIzaSyClmKNWlHYD_ZhqxKj7pzXfTju5h6J7o_c\")\n",
    "genai.configure(api_key=google_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import List, Optional\n",
    "from urllib.parse import urljoin, urlparse\n",
    "\n",
    "class Website:\n",
    "    \"\"\"\n",
    "    A utility class to represent and scrape website content with robust error handling.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, url: str, timeout: int = 10):\n",
    "        \"\"\"\n",
    "        Initialize the Website object by fetching and parsing webpage content.\n",
    "\n",
    "        Args:\n",
    "            url (str): The URL of the webpage to scrape\n",
    "            timeout (int, optional): Request timeout in seconds. Defaults to 10.\n",
    "        \"\"\"\n",
    "        self.url = url\n",
    "        self.title = \"No title found\"\n",
    "        self.text = \"\"\n",
    "        self.links = []\n",
    "        self.relevant_links = []\n",
    "\n",
    "        try:\n",
    "            response = self._fetch_webpage(url, timeout)\n",
    "            if response:\n",
    "                self._parse_webpage(response)\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {url}: {e}\")\n",
    "\n",
    "    def _fetch_webpage(self, url: str, timeout: int) -> Optional[requests.Response]:\n",
    "        \"\"\"\n",
    "        Fetch webpage content with error handling and validation.\n",
    "\n",
    "        Args:\n",
    "            url (str): URL to fetch\n",
    "            timeout (int): Request timeout in seconds\n",
    "\n",
    "        Returns:\n",
    "            Optional[requests.Response]: Response object or None\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Validate URL\n",
    "            parsed_url = urlparse(url)\n",
    "            if not all([parsed_url.scheme, parsed_url.netloc]):\n",
    "                print(f\"Invalid URL: {url}\")\n",
    "                return None\n",
    "\n",
    "            headers = {\n",
    "                'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
    "            }\n",
    "            response = requests.get(url, headers=headers, timeout=timeout)\n",
    "            response.raise_for_status()\n",
    "            return response\n",
    "        except (requests.RequestException, ValueError) as e:\n",
    "            print(f\"Request failed for {url}: {e}\")\n",
    "            return None\n",
    "\n",
    "    def _parse_webpage(self, response: requests.Response):\n",
    "        \"\"\"\n",
    "        Parse webpage content using BeautifulSoup.\n",
    "\n",
    "        Args:\n",
    "            response (requests.Response): Webpage response\n",
    "        \"\"\"\n",
    "        soup = BeautifulSoup(response.content, 'html.parser')\n",
    "        \n",
    "        # Extract title\n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "\n",
    "        if soup.body:\n",
    "            for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "                irrelevant.decompose()\n",
    "            self.text = soup.body.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "        links = [urljoin(self.url, link.get('href')) for link in soup.find_all('a') if link.get('href')]\n",
    "        self.links = list(set(links))  # Remove duplicates\n",
    "        self.relevant_links = self._filter_relevant_links(self.links)\n",
    "\n",
    "    def _filter_relevant_links(self, links: List[str]) -> List[str]:\n",
    "        \"\"\"\n",
    "        Filter links based on relevance keywords.\n",
    "\n",
    "        Args:\n",
    "            links (List[str]): List of webpage links\n",
    "\n",
    "        Returns:\n",
    "            List[str]: Filtered list of relevant links\n",
    "        \"\"\"\n",
    "        relevant_keywords = [\"about\", \"careers\", \"contact\", \"company\", \"jobs\"]\n",
    "        return [link for link in links if any(keyword in link.lower() for keyword in relevant_keywords)]\n",
    "\n",
    "    def get_contents(self) -> str:\n",
    "        \"\"\"\n",
    "        Get formatted webpage contents.\n",
    "\n",
    "        Returns:\n",
    "            str: Formatted string with webpage title and text\n",
    "        \"\"\"\n",
    "        return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\"\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"\"\"\n",
    "        String representation of the Website object.\n",
    "\n",
    "        Returns:\n",
    "            str: Descriptive string about the website\n",
    "        \"\"\"\n",
    "        return f\"Website(url='{self.url}', title='{self.title}', links={len(self.links)})\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from selenium import webdriver\n",
    "# from selenium.webdriver.chrome.service import Service\n",
    "# from selenium.webdriver.common.by import By\n",
    "# from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# class Website:\n",
    "#     \"\"\"\n",
    "#     A utility class to represent a Website that we have scraped, now with links\n",
    "#     \"\"\"\n",
    "\n",
    "#     def __init__(self, url):\n",
    "#         self.url = url\n",
    "\n",
    "#         # Set up Selenium WebDriver options\n",
    "#         options = Options()\n",
    "#         options.add_argument(\"headless\")  # Run in headless mode\n",
    "#         options.add_argument(\"--no-sandbox\")\n",
    "#         options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "#         # Initialize the WebDriver\n",
    "#         service = Service(\"C:/Users/anura/OneDrive/Desktop/llm_engineering/chromedriver-win64/chromedriver.exe\")\n",
    "#         driver = webdriver.Chrome(service=service, options=options)\n",
    "#         driver.get(url)\n",
    "\n",
    "#         # Wait for user to complete any manual verification if needed\n",
    "#         input(\"Please complete the verification in the browser and press Enter to continue...\")\n",
    "\n",
    "#         # Get the page source after JavaScript execution\n",
    "#         page_source = driver.page_source\n",
    "#         driver.quit()\n",
    "\n",
    "#         # Parse the page source with BeautifulSoup\n",
    "#         soup = BeautifulSoup(page_source, 'html.parser')\n",
    "#         self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        \n",
    "#         # Remove irrelevant tags\n",
    "#         for irrelevant in soup([\"script\", \"style\", \"img\", \"input\"]):\n",
    "#             irrelevant.decompose()\n",
    "        \n",
    "#         # Extract text content\n",
    "#         self.text = soup.get_text(separator=\"\\n\", strip=True)\n",
    "\n",
    "#         # Extract and filter links\n",
    "#         links = [link.get('href') for link in soup.find_all('a')]\n",
    "#         self.links = [link for link in links if link]\n",
    "#         self.relevant_links = self.filter_relevant_links(self.links)\n",
    "\n",
    "#     def filter_relevant_links(self, links: List[str]) -> List[str]:\n",
    "#         relevant_keywords = [\"about\", \"careers\", \"contact\", \"company\", \"jobs\"]\n",
    "#         return [link for link in links if any(keyword in link.lower() for keyword in relevant_keywords)]\n",
    "\n",
    "#     def get_contents(self):\n",
    "#         return f\"Webpage Title:\\n{self.title}\\nWebpage Contents:\\n{self.text}\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "link_system_prompt= \"Now You are an assistant that analyzes the contents of several relevant pages from a company website \\\n",
    "and creates a short brochure about the company for prospective customers, investors and recruits. Respond in markdown.\\\n",
    "Include details of company culture, customers and careers/jobs if you have the information. Include hyperlinks of social media platforms.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def stream_llama(prompt):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "      ]\n",
    "    stream = ollama.chat(\n",
    "        model='llama3.2',\n",
    "        messages=messages,\n",
    "        stream=True\n",
    "    )\n",
    "    result = \"\"\n",
    "    for chunk in stream:\n",
    "        result += chunk['message']['content']\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gemma(prompt):\n",
    "    messages=  [\n",
    "        {\"role\": \"system\", \"content\": link_system_prompt},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "       ]\n",
    "    result = ollama.chat(\n",
    "        model=\"gemma2\",\n",
    "        messages = messages,\n",
    "        stream=True\n",
    "    )\n",
    "    response = \"\"\n",
    "    for chunk in result:\n",
    "        response+=chunk['message']['content']\n",
    "        yield response\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_gemini(prompt):\n",
    "    model=genai.GenerativeModel(model_name=\"gemini-1.5-pro\",system_instruction=link_system_prompt)\n",
    "    response=model.generate_content(prompt,stream=True)\n",
    "    result=\"\"\n",
    "\n",
    "    for chunks in response:\n",
    "        if chunks.text:\n",
    "            result+=chunks.text\n",
    "            yield result\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stream_brochure(company_name, url, model):\n",
    "    prompt = f\"Please generate a company brochure for {company_name}.\\n\"\n",
    "    prompt += Website(url).get_contents()\n",
    "    if model==\"LLAMA3.2\":\n",
    "        result = stream_llama(prompt)\n",
    "    elif model==\"GEMMA2\":\n",
    "        result = stream_gemma(prompt)\n",
    "    elif model==\"GEMINI-1.5-PRO\":\n",
    "        result = stream_gemini(prompt)\n",
    "    else:\n",
    "        raise ValueError(\"Unknown model\")\n",
    "    yield from result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 101, in handle_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 78, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 207, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\blocks.py\", line 2015, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\blocks.py\", line 1574, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\utils.py\", line 710, in async_iteration\n",
      "    return await anext(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\utils.py\", line 704, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\utils.py\", line 687, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\utils.py\", line 848, in gen_wrapper\n",
      "    response = next(iterator)\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_6580\\4014550288.py\", line 12, in stream_brochure\n",
      "    yield from result\n",
      "  File \"C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_6580\\4015615653.py\", line 12, in stream_llama\n",
      "    for chunk in stream:\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\ollama\\_client.py\", line 80, in _stream\n",
      "    with self._client.stream(method, url, **kwargs) as r:\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_client.py\", line 880, in stream\n",
      "    response = self.send(\n",
      "               ^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 72, in map_httpcore_exceptions\n",
      "    yield\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 236, in handle_request\n",
      "    resp = self._pool.handle_request(req)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 256, in handle_request\n",
      "    raise exc from None\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py\", line 236, in handle_request\n",
      "    response = connection.handle_request(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 101, in handle_request\n",
      "    raise exc\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 78, in handle_request\n",
      "    stream = self._connect(request)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpcore\\_sync\\connection.py\", line 124, in _connect\n",
      "    stream = self._network_backend.connect_tcp(**kwargs)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpcore\\_backends\\sync.py\", line 207, in connect_tcp\n",
      "    with map_exceptions(exc_map):\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpcore\\_exceptions.py\", line 14, in map_exceptions\n",
      "    raise to_exc(exc) from exc\n",
      "httpcore.ConnectError: [WinError 10061] No connection could be made because the target machine actively refused it\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\queueing.py\", line 624, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\blocks.py\", line 2015, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\blocks.py\", line 1574, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\utils.py\", line 710, in async_iteration\n",
      "    return await anext(iterator)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\utils.py\", line 704, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\utils.py\", line 687, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\gradio\\utils.py\", line 848, in gen_wrapper\n",
      "    response = next(iterator)\n",
      "               ^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_6580\\4014550288.py\", line 12, in stream_brochure\n",
      "    yield from result\n",
      "  File \"C:\\Users\\anura\\AppData\\Local\\Temp\\ipykernel_6580\\1429295931.py\", line 12, in stream_gemma\n",
      "    for chunk in result:\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\ollama\\_client.py\", line 80, in _stream\n",
      "    with self._client.stream(method, url, **kwargs) as r:\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\contextlib.py\", line 137, in __enter__\n",
      "    return next(self.gen)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_client.py\", line 880, in stream\n",
      "    response = self.send(\n",
      "               ^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_client.py\", line 926, in send\n",
      "    response = self._send_handling_auth(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_client.py\", line 954, in _send_handling_auth\n",
      "    response = self._send_handling_redirects(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_client.py\", line 991, in _send_handling_redirects\n",
      "    response = self._send_single_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_client.py\", line 1027, in _send_single_request\n",
      "    response = transport.handle_request(request)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 235, in handle_request\n",
      "    with map_httpcore_exceptions():\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\contextlib.py\", line 158, in __exit__\n",
      "    self.gen.throw(typ, value, traceback)\n",
      "  File \"c:\\Users\\anura\\anaconda3\\envs\\llm_engineering\\Lib\\site-packages\\httpx\\_transports\\default.py\", line 89, in map_httpcore_exceptions\n",
      "    raise mapped_exc(message) from exc\n",
      "httpx.ConnectError: [WinError 10061] No connection could be made because the target machine actively refused it\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "view = gr.Interface(\n",
    "    fn=stream_brochure,\n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Company Name:\", placeholder=\"Enter the company name here\"),\n",
    "        gr.Textbox(label=\"Landing Page URL:\", placeholder=\"Enter the URL including http:// or https://\"),\n",
    "        gr.Dropdown([\"LLAMA3.2\", \"GEMMA2\",\"GEMINI-1.5-PRO\"], label=\"Select Model\")\n",
    "    ],\n",
    "    outputs=[gr.Markdown(label=\"Brochure:\")],\n",
    "    title=\"Company Brochure Generator\",\n",
    "    description=\"Generate a professional brochure for your company using AI models. Simply provide the company name, landing page URL, and select the model.\",\n",
    "    theme=\"default\",\n",
    "    # layout=\"vertical\",\n",
    "    flagging_mode=\"never\"\n",
    ")\n",
    "view.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_engineering",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
